{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3 (ipykernel)",
   "language": "python"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "code",
   "metadata": {
    "id": "tiCQyHAAhYwa",
    "ExecuteTime": {
     "end_time": "2025-01-16T18:03:33.696744Z",
     "start_time": "2025-01-16T18:03:33.687097Z"
    }
   },
   "source": [
    "import json\n",
    "\n",
    "#input and output file names\n",
    "JSON_FILE_NAME = \"db_final_flant5-large_kfs_1_kc_10\"\n",
    "OUTPUT_FILE_NAME = JSON_FILE_NAME + \"_RESULTS\"\n",
    "\n",
    "#load json file\n",
    "f = open(f'../results/{JSON_FILE_NAME}.json')\n",
    "output = json.load(f)\n",
    "\n",
    "#print(json.dumps(output, indent=4))"
   ],
   "outputs": [],
   "execution_count": 319
  },
  {
   "cell_type": "code",
   "source": [
    "import re\n",
    "import copy\n",
    "from collections import defaultdict\n",
    "\n",
    "def preprocessing(json_data):\n",
    "\n",
    "  def parse_entry(entry):\n",
    "    # Regular expression to capture the entity and years\n",
    "    match = re.match(r\"(.+?)\\s*\\(([\\d,\\s\\u2013\\-]*)\\)?\", entry)\n",
    "    if match:\n",
    "        entity = match.group(1).strip()  # Extract the entity name\n",
    "        timeline = match.group(2).strip() if match.group(2) else \"\"  # Extract the timeline if present\n",
    "        if timeline:\n",
    "            # Attempt to split timeline into valid integers, ignoring invalid entries\n",
    "            years = []\n",
    "            for part in timeline.split(\",\"):\n",
    "\n",
    "                try:\n",
    "                    # Support ranges (e.g., \"2010–2017\")\n",
    "                    if \"–\" in part:\n",
    "                        start, end = map(int, part.split(\"–\"))\n",
    "                        years.extend(range(start, end + 1))\n",
    "                    else:\n",
    "                        years.append(int(part))\n",
    "                except ValueError:\n",
    "                    pass  # Skip invalid entries\n",
    "            return {entity: years}\n",
    "        else:\n",
    "            return {entity: []}  # No timeline or invalid timeline\n",
    "    else:\n",
    "        # If the pattern doesn't match, assume the entire entry is an entity with no timeline\n",
    "        return {entry.strip(): []}\n",
    "\n",
    "  json_data_copy = copy.deepcopy(json_data)\n",
    "\n",
    "  for x in json_data_copy:\n",
    "    x[\"generated_answer\"] = list(dict.fromkeys(x[\"generated_answer\"])) # remove duplicates\n",
    "    parsed_generated_answer = [parse_entry(entry) for entry in x[\"generated_answer\"]]\n",
    "    parsed_ground_truth = [parse_entry(entry) for entry in x[\"ground_truth\"]]\n",
    "\n",
    "    x[\"generated_answer\"] = parsed_generated_answer\n",
    "    x[\"ground_truth\"] = parsed_ground_truth\n",
    "\n",
    "  return json_data_copy"
   ],
   "metadata": {
    "id": "9wXgDaVkgWX5",
    "ExecuteTime": {
     "end_time": "2025-01-16T18:03:33.712057Z",
     "start_time": "2025-01-16T18:03:33.704387Z"
    }
   },
   "outputs": [],
   "execution_count": 320
  },
  {
   "cell_type": "code",
   "source": [
    "#Entity-level evaluation\n",
    "\n",
    "def entity_precision_recall_f1_EM(data):\n",
    "  total_correct_generated = 0\n",
    "  total_generated = 0\n",
    "  total_ground_truth = 0\n",
    "  exact_match = 0\n",
    "  total = 0\n",
    "\n",
    "  for entry in data:\n",
    "\n",
    "      generated_entities = {list(d.keys())[0] for d in entry[\"generated_answer\"]}\n",
    "      ground_truth_entities = {list(d.keys())[0] for d in entry[\"ground_truth\"]}\n",
    "      correct_entities = generated_entities.intersection(ground_truth_entities)\n",
    "\n",
    "      total_correct_generated += len(correct_entities)\n",
    "      total_generated += len(generated_entities)\n",
    "      total_ground_truth += len(ground_truth_entities)\n",
    "\n",
    "      if generated_entities == ground_truth_entities:\n",
    "        exact_match += 1\n",
    "\n",
    "      total += 1\n",
    "\n",
    "  precision = total_correct_generated / total_generated\n",
    "  recall = total_correct_generated / total_ground_truth\n",
    "  f1 = 0.0\n",
    "  if (precision > 0.0 or recall > 0.0):\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "  EM = (exact_match / total)\n",
    "\n",
    "  return precision, recall, f1, EM"
   ],
   "metadata": {
    "id": "MTThZtccmbeO",
    "ExecuteTime": {
     "end_time": "2025-01-16T18:03:33.724325Z",
     "start_time": "2025-01-16T18:03:33.719124Z"
    }
   },
   "outputs": [],
   "execution_count": 321
  },
  {
   "cell_type": "code",
   "source": [
    "from collections import Counter\n",
    "\n",
    "#Timeline-level evaluation\n",
    "\n",
    "def timeline_precision_recall_f1(data):\n",
    "  total_correct_generated = 0\n",
    "  total_generated = 0\n",
    "  total_ground_truth = 0\n",
    "\n",
    "  for entry in data:\n",
    "\n",
    "      #print(entry)\n",
    "      generated_years = [list(d.values())[0] for d in entry[\"generated_answer\"]]\n",
    "      generated_years  = [year for sublist in generated_years for year in sublist]\n",
    "\n",
    "      ground_truth_years = [list(d.values())[0] for d in entry[\"ground_truth\"]]\n",
    "      ground_truth_years  = [year for sublist in ground_truth_years for year in sublist]\n",
    "\n",
    "      def match_lists(list1, list2):\n",
    "        match_count = 0\n",
    "        list2_copy = list2.copy()\n",
    "\n",
    "        for item in list1:\n",
    "            if item in list2_copy:\n",
    "                match_count += 1\n",
    "                list2_copy.remove(item)\n",
    "        return match_count\n",
    "\n",
    "      correct_years = match_lists(generated_years, ground_truth_years)\n",
    "\n",
    "      total_correct_generated += correct_years\n",
    "      total_generated += len(generated_years)\n",
    "      total_ground_truth += len(ground_truth_years)\n",
    "\n",
    "  precision = total_correct_generated / total_generated\n",
    "  recall = total_correct_generated / total_ground_truth\n",
    "  f1 = 0.0\n",
    "  if (precision > 0.0 or recall > 0.0):\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "\n",
    "  return precision, recall, f1\n",
    "\n",
    "def timeline_EM(data):\n",
    "\n",
    "  def check_timeline_EM(generated_timelines, ground_truth_timelines):\n",
    "    # Sort the inner lists\n",
    "    sorted_list1 = [sorted(inner_list) for inner_list in generated_timelines]\n",
    "    sorted_list2 = [sorted(inner_list) for inner_list in ground_truth_timelines]\n",
    "\n",
    "    # Sort the outer lists and compare\n",
    "    return sorted(sorted_list1) == sorted(sorted_list2)\n",
    "\n",
    "  exact_match = 0\n",
    "  total = 0\n",
    "\n",
    "  for entry in data:\n",
    "    generated_years = [list(d.values())[0] for d in entry[\"generated_answer\"]]\n",
    "    #print(generated_years)\n",
    "\n",
    "    ground_truth_years = [list(d.values())[0] for d in entry[\"ground_truth\"]]\n",
    "\n",
    "    if check_timeline_EM(generated_years, ground_truth_years):\n",
    "      exact_match += 1\n",
    "\n",
    "    total += 1\n",
    "\n",
    "  EM = (exact_match / total)\n",
    "  return EM"
   ],
   "metadata": {
    "id": "DmdHC7ZOGcdb",
    "ExecuteTime": {
     "end_time": "2025-01-16T18:03:33.740628Z",
     "start_time": "2025-01-16T18:03:33.732982Z"
    }
   },
   "outputs": [],
   "execution_count": 322
  },
  {
   "cell_type": "code",
   "source": [
    "# change list of dictionaries into one dictionary for comparisons\n",
    "def combine_generated_answers(data):\n",
    "    data_copy = copy.deepcopy(data)\n",
    "    combined = {}\n",
    "\n",
    "    # Iterate over each dictionary in the list\n",
    "    for item in data_copy[\"generated_answer\"]:\n",
    "        for key, value in item.items():\n",
    "            if key in combined:\n",
    "                # Merge and remove duplicates\n",
    "                combined[key] = sorted(set(combined[key] + value))\n",
    "            else:\n",
    "                combined[key] = value\n",
    "\n",
    "    # Replace the list of dictionaries with the combined result\n",
    "    data_copy[\"generated_answer\"] = [{k: v} for k, v in combined.items()]\n",
    "    return data_copy"
   ],
   "metadata": {
    "id": "3pGR6xTmA04m",
    "ExecuteTime": {
     "end_time": "2025-01-16T18:03:33.755445Z",
     "start_time": "2025-01-16T18:03:33.750699Z"
    }
   },
   "outputs": [],
   "execution_count": 323
  },
  {
   "cell_type": "code",
   "source": [
    "# Combined evaluation\n",
    "\n",
    "def combined_precision_recall_f1_EM(data):\n",
    "  total_correct_generated = 0\n",
    "  total_generated = 0\n",
    "  total_ground_truth = 0\n",
    "  exact_match = 0\n",
    "  total = 0\n",
    "\n",
    "  for entry in data:\n",
    "    # change list of dictionaries into one dictionary for comparisons\n",
    "    generated_answer_dict = {}\n",
    "    ground_truth_dict = {}\n",
    "\n",
    "    for d in entry['generated_answer']:\n",
    "      generated_answer_dict.update(d)\n",
    "\n",
    "    for d in entry['ground_truth']:\n",
    "      ground_truth_dict.update(d)\n",
    "\n",
    "    correct_generated = sum(1 for k, v in generated_answer_dict.items() if ground_truth_dict.get(k) == v)\n",
    "\n",
    "    total_correct_generated += correct_generated\n",
    "    total_generated += len(generated_answer_dict)\n",
    "    total_ground_truth += len(ground_truth_dict)\n",
    "\n",
    "    if (generated_answer_dict == ground_truth_dict):\n",
    "      exact_match += 1\n",
    "    total += 1\n",
    "\n",
    "  precision = total_correct_generated / total_generated\n",
    "  recall = total_correct_generated / total_ground_truth\n",
    "  f1 = 0.0\n",
    "  if (precision > 0.0 or recall > 0.0):\n",
    "    f1 = 2 * precision * recall / (precision + recall)\n",
    "  EM = (exact_match / total)\n",
    "\n",
    "  return precision, recall, f1, EM"
   ],
   "metadata": {
    "id": "4tCROaONRfyA",
    "ExecuteTime": {
     "end_time": "2025-01-16T18:03:33.771082Z",
     "start_time": "2025-01-16T18:03:33.765039Z"
    }
   },
   "outputs": [],
   "execution_count": 324
  },
  {
   "cell_type": "code",
   "source": [
    "preprocessed_data = preprocessing(output)\n",
    "#print(json.dumps(preprocessed_data, indent=4))"
   ],
   "metadata": {
    "id": "aBOcnz7jXJ5z",
    "ExecuteTime": {
     "end_time": "2025-01-16T18:03:33.806133Z",
     "start_time": "2025-01-16T18:03:33.780852Z"
    }
   },
   "outputs": [],
   "execution_count": 325
  },
  {
   "cell_type": "code",
   "source": [
    "# print all fully correct answers\n",
    "\n",
    "#for entry in preprocessed_data:\n",
    "#  if entry['generated_answer'] == entry['ground_truth']:\n",
    "#    print(entry)"
   ],
   "metadata": {
    "id": "IJXAdfy7rjav",
    "ExecuteTime": {
     "end_time": "2025-01-16T18:03:33.820486Z",
     "start_time": "2025-01-16T18:03:33.816919Z"
    }
   },
   "outputs": [],
   "execution_count": 326
  },
  {
   "cell_type": "code",
   "source": [
    "entity_results = entity_precision_recall_f1_EM(preprocessed_data)\n",
    "timeline_results_pre_rec_f1 = timeline_precision_recall_f1(preprocessed_data)\n",
    "timeline_results_EM = timeline_EM(preprocessed_data)\n",
    "\n",
    "new_preprocessed_data = [combine_generated_answers(entry) for entry in preprocessed_data]\n",
    "combined_results = combined_precision_recall_f1_EM(new_preprocessed_data)"
   ],
   "metadata": {
    "id": "-hToMsfBdBfo",
    "ExecuteTime": {
     "end_time": "2025-01-16T18:03:33.865994Z",
     "start_time": "2025-01-16T18:03:33.829526Z"
    }
   },
   "outputs": [],
   "execution_count": 327
  },
  {
   "cell_type": "code",
   "source": [
    "result_string = \"EVALUATION OF \" + JSON_FILE_NAME + \"\\n\"\n",
    "result_string +=  \"########################\\n\"\n",
    "\n",
    "result_string +=  \"########################\\n\"\n",
    "result_string += \"Entity evaluation\\n\"\n",
    "result_string += \"########################\\n\"\n",
    "\n",
    "result_string += f\"Precision:\\t\\t {entity_results[0]}\\n\"\n",
    "result_string += f\"Recall (completeness):\\t {entity_results[1]}\\n\"\n",
    "result_string += f\"f1:\\t\\t\\t {entity_results[2]}\\n\"\n",
    "result_string += f\"EM:\\t\\t\\t {entity_results[3]}\\n\\n\"\n",
    "\n",
    "result_string += \"########################\\n\"\n",
    "result_string += \"Timeline evaluation\\n\"\n",
    "result_string += \"########################\\n\"\n",
    "\n",
    "result_string += f\"Precision:\\t\\t {timeline_results_pre_rec_f1[0]}\\n\"\n",
    "result_string += f\"Recall (completeness):\\t {timeline_results_pre_rec_f1[1]}\\n\"\n",
    "result_string += f\"f1:\\t\\t\\t {timeline_results_pre_rec_f1[2]}\\n\"\n",
    "result_string += f\"EM:\\t\\t\\t {timeline_results_EM}\\n\\n\"\n",
    "\n",
    "result_string += \"########################\\n\"\n",
    "result_string += \"Combined evaluation\\n\"\n",
    "result_string += \"########################\\n\"\n",
    "\n",
    "result_string += f\"Precision:\\t\\t {combined_results[0]}\\n\"\n",
    "result_string += f\"Recall (completeness):\\t {combined_results[1]}\\n\"\n",
    "result_string += f\"f1:\\t\\t\\t {combined_results[2]}\\n\"\n",
    "result_string += f\"EM:\\t\\t\\t {combined_results[3]}\\n\\n\"\n",
    "\n",
    "result_string += \"for copy paste into the table:\\n\"\n",
    "result_string += f\"{entity_results[0]:.4f} & {entity_results[1]:.4f} & {entity_results[2]:.4f} & {entity_results[3]:.4f}\\n\"\n",
    "result_string += f\"{timeline_results_pre_rec_f1[0]:.4f} & {timeline_results_pre_rec_f1[1]:.4f} & {timeline_results_pre_rec_f1[2]:.4f} & {timeline_results_EM:.4f}\\n\"\n",
    "result_string += f\"{combined_results[0]:.4f} & {combined_results[1]:.4f} & {combined_results[2]:.4f} & {combined_results[3]:.4f}\\n\"\n",
    "\n",
    "print(result_string)\n",
    "\n",
    "f = open(f\"../results/{OUTPUT_FILE_NAME}.txt\", \"w\")\n",
    "f.write(result_string)\n",
    "f.close()\n",
    "\n",
    "print(f'Results saved to {OUTPUT_FILE_NAME}.txt')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9IEWXsFmccGG",
    "outputId": "45093242-b9d7-4cd1-df9e-5a2352d01093",
    "ExecuteTime": {
     "end_time": "2025-01-16T18:03:33.883224Z",
     "start_time": "2025-01-16T18:03:33.875465Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EVALUATION OF db_final_flant5-large_kfs_1_kc_10\n",
      "########################\n",
      "########################\n",
      "Entity evaluation\n",
      "########################\n",
      "Precision:\t\t 0.07792207792207792\n",
      "Recall (completeness):\t 0.05886075949367089\n",
      "f1:\t\t\t 0.06706327744726878\n",
      "EM:\t\t\t 0.008403361344537815\n",
      "\n",
      "########################\n",
      "Timeline evaluation\n",
      "########################\n",
      "Precision:\t\t 0.7204666990763248\n",
      "Recall (completeness):\t 0.36777235503350153\n",
      "f1:\t\t\t 0.4869660460021905\n",
      "EM:\t\t\t 0.009337068160597572\n",
      "\n",
      "########################\n",
      "Combined evaluation\n",
      "########################\n",
      "Precision:\t\t 0.008378718056137411\n",
      "Recall (completeness):\t 0.006329113924050633\n",
      "f1:\t\t\t 0.0072111051018568595\n",
      "EM:\t\t\t 0.0028011204481792717\n",
      "\n",
      "for copy paste into the table:\n",
      "0.0779 & 0.0589 & 0.0671 & 0.0084\n",
      "0.7205 & 0.3678 & 0.4870 & 0.0093\n",
      "0.0084 & 0.0063 & 0.0072 & 0.0028\n",
      "\n",
      "Results saved to db_final_flant5-large_kfs_1_kc_10_RESULTS.txt\n"
     ]
    }
   ],
   "execution_count": 328
  }
 ]
}
